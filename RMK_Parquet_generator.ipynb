{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssyKEYgoZVJY"
   },
   "source": [
    "### 1. Generating Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "spQ8YpWrW8cG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import random\n",
    "import string\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "AKmm3_QCfBWT"
   },
   "outputs": [],
   "source": [
    "def generate_dummy_data(n_rows: int, n_columns: int) -> dict:\n",
    "    '''This function takes as an input the number of rows and columns\n",
    "    of a table and generates a dictionary with the given\n",
    "    dimensions, where keys represent columns and values represent rows,\n",
    "    filled with dummy data.\n",
    "\n",
    "    Parameters:\n",
    "        n_rows (int): the number of rows for the data being generated\n",
    "        n_columns (int): the number of columns for the data\n",
    "\n",
    "    Returns:\n",
    "        dict: a dictionary with n_columns number of keys and n_rows\n",
    "        number of values per each key. Each key represents a data type\n",
    "        and the values are randomly generated data for that type.\n",
    "    '''\n",
    "\n",
    "    random.seed(10)\n",
    "\n",
    "    letters = string.ascii_letters\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    for i_col in range(n_columns):\n",
    "        col_name = f\"col_{i_col + 1}\"\n",
    "\n",
    "        # Generates dummy data with different data types\n",
    "        if i_col == 0:\n",
    "            # Random datetime column\n",
    "            col_name += '_datetime'\n",
    "            timestamps = []\n",
    "            # Create a list with random pyarrow.TimestampScalar objects\n",
    "            while len(timestamps) < n_rows:\n",
    "                random_epoch_time = random.randint(0, 2**30)\n",
    "                timestamp = datetime.datetime.fromtimestamp(random_epoch_time)\n",
    "                timestamps.append(timestamp)\n",
    "            # Convert the list to a pyarrow array\n",
    "            pyarrow_timestamps = pa.array(timestamps, type=pa.timestamp('ns'))\n",
    "            data[col_name] = pyarrow_timestamps\n",
    "\n",
    "        if i_col % 7 == 0:\n",
    "            # Random integer column\n",
    "            col_name += '_int'\n",
    "            data[col_name] = pa.array(\n",
    "                random.sample(range(0, random.randint(1, 1000)), n_rows),\n",
    "                type=pa.uint32())\n",
    "\n",
    "        if i_col % 7 == 1:\n",
    "            # Random float column with values between 0 and 1\n",
    "            col_name += '_float'\n",
    "            floatlist = []\n",
    "            while len(floatlist) < n_rows:\n",
    "                number = random.random()\n",
    "                floatlist.append(number)\n",
    "            data[col_name] = pa.array(floatlist, type=pa.float32())\n",
    "\n",
    "        if i_col % 7 == 2:\n",
    "            # Random boolean column\n",
    "            col_name += '_bool'\n",
    "            boollist = []\n",
    "            while len(boollist) < n_rows:\n",
    "                boolean = bool(random.getrandbits(1))\n",
    "                boollist.append(boolean)\n",
    "            data[col_name] = pa.array(boollist, type=pa.bool_())\n",
    "\n",
    "        if i_col % 7 == 3:\n",
    "            # Random exponential distribution float column\n",
    "            col_name += '_float'\n",
    "            expolist = []\n",
    "            while len(expolist) < n_rows:\n",
    "                expo = random.expovariate(random.randint(1, 20))\n",
    "                expolist.append(expo)\n",
    "            data[col_name] = pa.array(expolist, type=pa.float32())\n",
    "\n",
    "        if i_col % 7 == 4:\n",
    "            # Random string column\n",
    "            col_name += '_str'\n",
    "            stringlist = []\n",
    "            while len(stringlist) < n_rows:\n",
    "                random_string =''.join(random.choice(letters) for _ in range(\n",
    "                    random.randint(5, 8)))\n",
    "                stringlist.append(random_string)\n",
    "            data[col_name] = pa.array(stringlist, type=pa.string())\n",
    "\n",
    "        if i_col % 7 == 5:\n",
    "            # Random normal distribution float column with a random mean\n",
    "            col_name += '_float'\n",
    "            normlist = []\n",
    "            while len(normlist) < n_rows:\n",
    "              norm = random.gauss(mu=random.randint(15, 50),\n",
    "                                  sigma=random.randint(1, 25))\n",
    "              normlist.append(norm)\n",
    "            data[col_name] = pa.array(normlist, type=pa.float32())\n",
    "\n",
    "        if i_col % 7 == 6:\n",
    "            # Random integer column\n",
    "            col_name += '_int'\n",
    "            data[col_name] = pa.array(random.choices(\n",
    "                range(random.randint(-10, -1), random.randint(0, 10)),\n",
    "                k=n_rows), type = pa.int32())\n",
    "\n",
    "    return data\n",
    "\n",
    "def generate_parquet_file(n_rows: int, n_columns: int,\n",
    "                          save_path: str, filename: str) -> None:\n",
    "    '''This function takes as input the number of rows and columns of\n",
    "    the table that is being generated and the file name for the\n",
    "    Parquet file created from the table.\n",
    "\n",
    "    Parameters:\n",
    "        rows (int): the number of rows for the table being generated\n",
    "        columns (int): the number of columns for the table\n",
    "        filename (str): the file name for the Parquet file created from\n",
    "             the table\n",
    "\n",
    "    Returns:\n",
    "        None: downloads a Parquet file containing a table with the given\n",
    "        dimensions, filled with randomly generated dummy data and\n",
    "        various data types\n",
    "    '''\n",
    "    # Validity checks\n",
    "    if not(n_rows and n_rows > 0 and\n",
    "           n_rows < 10e6 and isinstance(n_rows, int)):\n",
    "        raise ValueError('Invalid input dimensions!')\n",
    "\n",
    "    if not(n_columns and n_columns > 0 and\n",
    "           n_columns < 10e6 and isinstance(n_rows, int)):\n",
    "        raise ValueError('Invalid input dimensions!')\n",
    "\n",
    "    else:\n",
    "        # Generate dummy data\n",
    "        dummy_data = generate_dummy_data(n_rows, n_columns)\n",
    "\n",
    "        # Convert DataFrame to Arrow Table\n",
    "        table = pa.Table.from_pydict(dummy_data)\n",
    "\n",
    "        # Chech if save path exists\n",
    "        if os.path.exists(save_path) == False:\n",
    "            raise ValueError('Save path does not exist')\n",
    "\n",
    "        # Write Arrow Table to Parquet file\n",
    "        # .parquet added to file name automatically\n",
    "        file_path = os.path.join(save_path, filename + '.parquet')\n",
    "        pq.write_table(table, file_path)\n",
    "        print(f\"Parquet file '{filename}' generated successfully.\")\n",
    "\n",
    "    # Sample run\n",
    "    #\n",
    "    # import os\n",
    "    # import datetime\n",
    "    # import random\n",
    "    # import string\n",
    "    # import pyarrow as pa\n",
    "    # import pyarrow.parquet as pq\n",
    "    #\n",
    "    # generate_parquet_file(10, 10, 'C:\\\\Users\\\\user', 'dummy_data')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
