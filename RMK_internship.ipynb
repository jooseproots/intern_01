{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Generating Test Data"
      ],
      "metadata": {
        "id": "ssyKEYgoZVJY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "spQ8YpWrW8cG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dummy_data(rows: int, columns: int) -> pd.DataFrame:\n",
        "    '''This function takes as an input the number of rows and columns\n",
        "    of a table and generates a pandas Dataframe with the given\n",
        "    dimensions, filled with dummy data.\n",
        "\n",
        "    Parameters:\n",
        "        rows (int): the number of rows for the Dataframe being generated\n",
        "        columns (int): the number of columns for the DataFrame\n",
        "\n",
        "    Returns:\n",
        "        pd.Dataframe: a pandas Dataframe with the given dimensions,\n",
        "        filled with randomly generated dummy data and various data types\n",
        "    '''\n",
        "\n",
        "    data = {}\n",
        "\n",
        "    for col in range(int(columns)):\n",
        "        col_name = f\"col_{col}\"\n",
        "\n",
        "        # Generates dummy data with different data types\n",
        "        if col == 0:\n",
        "            data[col_name] = pd.date_range(start='2022-01-01',\n",
        "                                           freq='h',\n",
        "                                           periods=int(rows)).tolist()\n",
        "        elif col % 7 == 0:\n",
        "            data[col_name] = np.random.randint(\n",
        "                low=0,\n",
        "                high=(np.random.randint(1, 1000)),\n",
        "                size=int(rows))\n",
        "        elif col % 7 == 1:\n",
        "            data[col_name] = np.random.rand(int(rows))\n",
        "        elif col % 7 == 2:\n",
        "            data[col_name] = np.random.choice([True, False], size=int(rows))\n",
        "        elif col % 7 == 3:\n",
        "            data[col_name] = np.random.exponential(\n",
        "                scale=(np.random.randint(1, 20)),\n",
        "                size=int(rows))\n",
        "        elif col % 7 == 4:\n",
        "            data[col_name] = np.random.normal(loc=0.0,\n",
        "                                              scale=(np.random.randint(1, 30)),\n",
        "                                              size=int(rows))\n",
        "        elif col % 7 == 5:\n",
        "            data[col_name] = np.random.normal(loc=(np.random.randint(15, 50)),\n",
        "                                              scale=(np.random.randint(1, 25)),\n",
        "                                              size=int(rows))\n",
        "        else:\n",
        "            data[col_name] = np.random.choice(\n",
        "                range(1, (np.random.randint(3, 30))),\n",
        "                size=int(rows),\n",
        "                replace=True)\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def generate_parquet_file(rows: int, columns: int, filename: str) -> pq.ParquetFile:\n",
        "    '''This function takes as input the number of rows and columns of\n",
        "    the table that is being generated and the file name for the\n",
        "    Parquet file created from the table.\n",
        "\n",
        "    Parameters:\n",
        "        rows (int): the number of rows for the table being generated\n",
        "        columns (int): the number of columns for the table\n",
        "        filename (str): the file name for the Parquet file created from the table\n",
        "\n",
        "    Returns:\n",
        "        pq.ParquetFile: a Parquet file containing a table with the given\n",
        "        dimensions, filled with randomly generated dummy data and\n",
        "        various data types\n",
        "    '''\n",
        "\n",
        "    if rows <= 0 or columns <= 0:\n",
        "        print('Invalid dimensions.')\n",
        "    elif rows > 30e6 or columns > 10030e6:\n",
        "        print('Table size exceeds the limit.')\n",
        "    else:\n",
        "        # Generate dummy data\n",
        "        dummy_data = generate_dummy_data(rows, columns)\n",
        "\n",
        "        # Convert DataFrame to Arrow Table\n",
        "        table = pa.Table.from_pandas(dummy_data)\n",
        "\n",
        "        # Write Arrow Table to Parquet file\n",
        "        pq.write_table(table, filename + '.parquet')\n",
        "        print(f\"Parquet file '{filename}' generated successfully.\")"
      ],
      "metadata": {
        "id": "AKmm3_QCfBWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Table size vs file size\n",
        "\n",
        "100 x 100 - 119 KB\n",
        "\n",
        "1000 x 1000 cells - 6.2 MB\n",
        "\n",
        "10000 x 10000 cells - 564 MB\n",
        "\n",
        "If we assume that the file size increases linearly with the table size, then a 10e6 x 10e6 table would be approximately 500 TB"
      ],
      "metadata": {
        "id": "y-VYASLcEORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Graphing Database Schemas"
      ],
      "metadata": {
        "id": "T-HBKpyXpC7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pros and cons of using Mermaid chart for database schemas:\n",
        "\n",
        "Pros:\n",
        "-Easy to write\n",
        "-Code easy to read\n",
        "\n",
        "Cons:\n",
        "-Cannot link keys to keys, only tables to tables"
      ],
      "metadata": {
        "id": "wcA1RN4ylQ95"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![](https://mermaid.ink/img/pako:eNrVWduO0zAQ_ZUqTyBRBEggyDN_wGsly3Vmt9YmceRLobT9d8ZOmjStb13CA33odjvHx545M-PYPRZMVFCUBcjvnD5L2mzaFb42RWe2NWfvhSI7rrSQB6WhI52E_aZYHXuUffFq1ZoGJGdvPn59O31vkVwYRXyA86a9mYfVBieQDShFnyE2xWoyKGEkA9KiC6s9lWxH5ZsvH64RFSjNW6q5aGMwVlPeQEW2hxhqWNxo_fTps8dMNFKt7JvStOn071XI51Zo_sSZW51iO2is36fTei2OftCmKDEY6wGbQZahU0ubuUez4DHJO8u40vBL5_ixKaLGnBX1q_fbYA-tJvrQAQkN19B0NdVhgFuR47jW-dbeUSwGwJS8B3my92dFKi6B2ULxiDizE6q15FujrUJO0MnEqwRzRvwmtoi2tfgJkmRBmQQMJy4D36_zekKYrkogKNN8P2n6LZBl_gVwFJRgiSoVdSYJm7wNiz9hOqG4W1RO9wrqe_RRh5QbB8bkmEB7WhuIVuZ8XaIDeanDs1ivT6dwnj2UlzPmhzweBwYk8bukDi3bSdFyNYwVL2CnPi3gVIj7IbcsCcEi0Lj_OYKkSg00W5Bqx7uFxJkR5uzXVNrWGjKzHa-roHWaLFJaz1KYmH1YQbJppXH9YpNESVhc6PMQ9fvYO08X0vHClSFhH-Ck20lYpFnXgtHaa1lil0hvBcO2lcSlci1dwlivIFtaW8D9HP4i7mcdG7QKpMAgqVO_HxJWfs6WnQTpZ4NF96CYWGnsXwUz1K_Lma9ZVZaeLFG8HmKjQC7UCQaqh54AQwjLle4UKVSkUSzRDp64VBn7QRpGc2hSqIorPFdkPVQngdBQXhNaVRISD7U5SIx1hTsix84cOsjVYEN96Wn1wavZoy2Pdt0lKX0HnsFU3ibT-ub_MGtGqjuWFzi8Oo_v3XrCzDUSPFV7tbRynHl9-RCkyXBjAMdy5gKZbWofP-TF4hxsTummN3qMLcqNCHanhzerge6_36vyAvmahv-PNsDbXOU1lr4y2_G5KpULUzXbT54y9lHmFIIbRjiJZMxM7PsjRtjsWrw0rX-76VstRhDw-8N9iQUvLU33LKm9aaT2yJ-zP1NNt1QNV4X-81ZPTbbGnVGMPV_FkXuM9vUD8cxztza_ScjKShmYIei0vSf1Nf7JugMq9Ra7lksY-43Nw-FvjPR4fRfn0KGLOjRGPBtV9geOd_5hjLIdkJrjglp73BRShy4Scf60QA4WVCca4KsQ5gZlHBJJrkT-5V269Ncbvj4xS5Ck8q-kfii7HppjgUujKPkyJ5bQlIscD6IZdrncCpWFs0ObvhoLtyqjpvt3dX13VrwrkBMbdVWUvaubQvc_dpT4saLyxf4CYXHUaPEDJytKLQ28K_rzxvArV1E-0VrB-Q_1i9Qq?type=png)](https://mermaid.live/edit#pako:eNrVWduO0zAQ_ZUqTyBRBEggyDN_wGsly3Vmt9YmceRLobT9d8ZOmjStb13CA33odjvHx545M-PYPRZMVFCUBcjvnD5L2mzaFb42RWe2NWfvhSI7rrSQB6WhI52E_aZYHXuUffFq1ZoGJGdvPn59O31vkVwYRXyA86a9mYfVBieQDShFnyE2xWoyKGEkA9KiC6s9lWxH5ZsvH64RFSjNW6q5aGMwVlPeQEW2hxhqWNxo_fTps8dMNFKt7JvStOn071XI51Zo_sSZW51iO2is36fTei2OftCmKDEY6wGbQZahU0ubuUez4DHJO8u40vBL5_ixKaLGnBX1q_fbYA-tJvrQAQkN19B0NdVhgFuR47jW-dbeUSwGwJS8B3my92dFKi6B2ULxiDizE6q15FujrUJO0MnEqwRzRvwmtoi2tfgJkmRBmQQMJy4D36_zekKYrkogKNN8P2n6LZBl_gVwFJRgiSoVdSYJm7wNiz9hOqG4W1RO9wrqe_RRh5QbB8bkmEB7WhuIVuZ8XaIDeanDs1ivT6dwnj2UlzPmhzweBwYk8bukDi3bSdFyNYwVL2CnPi3gVIj7IbcsCcEi0Lj_OYKkSg00W5Bqx7uFxJkR5uzXVNrWGjKzHa-roHWaLFJaz1KYmH1YQbJppXH9YpNESVhc6PMQ9fvYO08X0vHClSFhH-Ck20lYpFnXgtHaa1lil0hvBcO2lcSlci1dwlivIFtaW8D9HP4i7mcdG7QKpMAgqVO_HxJWfs6WnQTpZ4NF96CYWGnsXwUz1K_Lma9ZVZaeLFG8HmKjQC7UCQaqh54AQwjLle4UKVSkUSzRDp64VBn7QRpGc2hSqIorPFdkPVQngdBQXhNaVRISD7U5SIx1hTsix84cOsjVYEN96Wn1wavZoy2Pdt0lKX0HnsFU3ibT-ub_MGtGqjuWFzi8Oo_v3XrCzDUSPFV7tbRynHl9-RCkyXBjAMdy5gKZbWofP-TF4hxsTummN3qMLcqNCHanhzerge6_36vyAvmahv-PNsDbXOU1lr4y2_G5KpULUzXbT54y9lHmFIIbRjiJZMxM7PsjRtjsWrw0rX-76VstRhDw-8N9iQUvLU33LKm9aaT2yJ-zP1NNt1QNV4X-81ZPTbbGnVGMPV_FkXuM9vUD8cxztza_ScjKShmYIei0vSf1Nf7JugMq9Ra7lksY-43Nw-FvjPR4fRfn0KGLOjRGPBtV9geOd_5hjLIdkJrjglp73BRShy4Scf60QA4WVCca4KsQ5gZlHBJJrkT-5V269Ncbvj4xS5Ck8q-kfii7HppjgUujKPkyJ5bQlIscD6IZdrncCpWFs0ObvhoLtyqjpvt3dX13VrwrkBMbdVWUvaubQvc_dpT4saLyxf4CYXHUaPEDJytKLQ28K_rzxvArV1E-0VrB-Q_1i9Qq)"
      ],
      "metadata": {
        "id": "X7l2YJdlYYpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the code for the diagram:"
      ],
      "metadata": {
        "id": "-sPwdie0YNSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "erDiagram\n",
        "\n",
        "    \"public.os_historystep_prev\" {\n",
        "        id numeric(18)\n",
        "        previous_id numeric(18)\n",
        "    }\n",
        "\n",
        "    \"public.clustermessage\" {\n",
        "        id numeric(18)\n",
        "        source_node varchar(60)\n",
        "        destination_node varchar(60)\n",
        "        claimed_by_node varchar(60)\n",
        "        message varchar(225)\n",
        "        message_time timestamptz\n",
        "    }\n",
        "\n",
        "    \"public.notificationscheme\" ||--o{ \"public.notification\": id-scheme\n",
        "    \"public.notificationscheme\" {\n",
        "        id numeric(18)\n",
        "        name varchar(225)\n",
        "        description text\n",
        "    }\n",
        "\n",
        "    \"public.notification\"\n",
        "    \"public.notification\" {\n",
        "        id numeric(18)\n",
        "        scheme numeric(18)\n",
        "        event_type_id numeric(18)\n",
        "        template_id numeric(18)\n",
        "        notif_type varchar(60)\n",
        "        notif_parameter varchar(60)\n",
        "    }\n",
        "\n",
        "    \"public.cwd_directory\" ||--o{ \"public.cwd_directory_attribute\" : id-directory_id\n",
        "    \"public.cwd_directory\" {\n",
        "        id numeric(18)\n",
        "        directory_name varchar(225)\n",
        "        lower_directory_name varchar(225)\n",
        "        created_date timestamptz\n",
        "        updated_date timestamptz\n",
        "        active numeric(9)\n",
        "        description varchar(225)\n",
        "        impl_class varchar(225)\n",
        "        lower_impl_class varchar(225)\n",
        "        directory_type varchar(60)\n",
        "        directory_position numeric(18)\n",
        "    }\n",
        "\n",
        "    \"public.cwd_directory_attribute\" {\n",
        "        directory_id numeric(18)\n",
        "        attribute_name varchar(225)\n",
        "        attribute_value text\n",
        "    }\n",
        "\n",
        "    \"public.cwd_directory_operation\" }o--|| \"public.cwd_directory\" : id-directory_id\n",
        "    \"public.cwd_directory_operation\" {\n",
        "        directory_id numeric(18)\n",
        "        operation_type varchar(60)\n",
        "    }\n",
        "\n",
        "    \"public.cwd_synchronisation_token\" |o--|| \"public.cwd_directory\" : id-directory_id\n",
        "    \"public.cwd_synchronisation_token\" {\n",
        "        directory_id numeric(18)\n",
        "        sync_status_token text\n",
        "    }\n",
        "\n",
        "    \"public.cwd_membership\" }o--|| \"public.cwd_directory\" : id-directory_id\n",
        "    \"public.cwd_membership\" {\n",
        "        id numeric(18)\n",
        "        parent_id numeric(18)\n",
        "        child_id numeric(18)\n",
        "        membership_type varchar(60)\n",
        "        group_type varchar(60)\n",
        "        parent_name varchar(225)\n",
        "        lower_parent_name varchar(225)\n",
        "        child_name varchar(225)\n",
        "        lower_child_name varchar(225)\n",
        "        directory_id numeric(18)\n",
        "    }\n",
        "    \n",
        "    \"public.cwd_group\" }o--|| \"public.cwd_directory\" : id-directory_id\n",
        "    \"public.cwd_group\" {\n",
        "        id numeric(18)\n",
        "        group_name varchar(225)\n",
        "        lower_group_name varchar(225)\n",
        "        active numeric(9)\n",
        "        local numeric(9)\n",
        "        created_date timestamptz\n",
        "        updated_date timestamptz\n",
        "        description varchar(225)\n",
        "        lower_description varchar(225)\n",
        "        group_type varchar(60)\n",
        "        directory_id numeric(18)\n",
        "        external_id varchar(225)\n",
        "    }\n",
        "\n",
        "    \"public.cwd_group_attributes\" }o--|| \"public.cwd_group\": id-group_id\n",
        "    \"public.cwd_group_attributes\" {\n",
        "        id numeric(18)\n",
        "        group_id numeric(18)\n",
        "        directory_id numeric(18)\n",
        "        attribute_name varchar(225)\n",
        "        attribute_value varchar(225)\n",
        "        lower_attribute_value varchar(225)\n",
        "    }\n",
        "\n",
        "    \"public.cwd_group_attributes\" }o--|| \"public.cwd_synchronisation_token\" : directory_id-directory_id\n",
        "    \"public.cwd_group_attributes\" }o--|| \"public.cwd_directory\" : id-directory_id\n",
        "\n",
        "    \"public.cwd_user\" }o--|| \"public.cwd_directory\" : id-directory_id\n",
        "    \"public.cwd_user\" {\n",
        "        id numeric(18)\n",
        "        directory_id numeric(18)\n",
        "        user_name varchar(225)\n",
        "        lower_user_name varchar(225)\n",
        "        active numeric(9)\n",
        "        created_date timestamptz\n",
        "        updated_date timestamptz\n",
        "        first_name varchar(225)\n",
        "        lower_first_name varchar(225)\n",
        "        last_name varchar(225)\n",
        "        lower_last_name varchar(225)\n",
        "        display_name varchar(225)\n",
        "        lower_display_name varchar(225)\n",
        "        email_address varchar(225)\n",
        "        lower_email_address varchar(225)\n",
        "        credential varchar(225)\n",
        "        deleted_externally numeric(9)\n",
        "        external_id varchar(225)\n",
        "    }\n",
        "\n",
        "    \"public.app_user\" ||--o{ \"public.cwd_user\" : lower_user_name-lower_user_name\n",
        "    \"public.app_user\" {\n",
        "        id numeric(18)\n",
        "        user_key varchar(225)\n",
        "        lower_user_name varchar(225)\n",
        "    }\n",
        "\n",
        "    \"public.feature\" }o--|| \"public.app_user\" : user_key-user_key\n",
        "    \"public.feature\" {\n",
        "        id numeric(18)\n",
        "        feature_name varchar(225)\n",
        "        feature_type varchar(10)\n",
        "        user_key varchar(225)\n",
        "    }\n",
        "\n",
        "    \"public.cwd_user_attributes\" }o--|| \"public.cwd_user\" : id-user_id\n",
        "    \"public.cwd_user_attributes\" {\n",
        "        id numeric(18)\n",
        "        user_id numeric(18)\n",
        "        directory_id numeric(18)\n",
        "        attribute_name varchar(225)\n",
        "        attribute_value varchar(225)\n",
        "        lower_attribute_value varchar(225)\n",
        "    }\n",
        "\n",
        "    \"public.cwd_user_attributes\" }o--|| \"public.cwd_directory\" : id-directory_id\n",
        "    \"public.cwd_user_attributes\" }o--|| \"public.cwd_synchronisation_token\" : directory_id-directory_id\n",
        "\n",
        "    \"public.filtersubscription\" }o--|| \"public.cwd_user\" : user_name-username\n",
        "    \"public.filtersubscription\"{\n",
        "        id numeric(18)\n",
        "        filter_i_d numeric(18)\n",
        "        username varchar(60)\n",
        "        groupname varchar(60)\n",
        "        last_run timestamptz\n",
        "        email_on_empty varchar(10)\n",
        "    }\n",
        "\n",
        "    \"public.clusterupgradestate\"{\n",
        "        id numeric(18)\n",
        "        database_time numeric(18)\n",
        "        cluster_build_number numeric(18)\n",
        "        cluster_version varchar(60)\n",
        "        state varchar(60)\n",
        "        order_number numeric(18)\n",
        "    }\n",
        "\n",
        "    \"public.clusternode\" ||--o{ \"public.clusternodeheartbeat\" : node_id-node_id\n",
        "    \"public.clusternode\"{\n",
        "        node_id varchar(60)\n",
        "        node_state varchar(60)\n",
        "        timestamp numeric(18)\n",
        "        ip varchar(60)\n",
        "        cache_listener_port numeric(18)\n",
        "        node_build_number numeric(18)\n",
        "        node_version varchar(60)\n",
        "    }\n",
        "\n",
        "    \"public.clusternodeheartbeat\"{\n",
        "        node_id varchar(60)\n",
        "        heartbeat_time numeric(18)\n",
        "        database_time numeric(18)\n",
        "    }\n",
        "\n",
        "    \"public.cwd_synchronisation_status\" }o--|| \"public.clusternode\" : node_id-node_id\n",
        "    \"public.cwd_synchronisation_status\" }o--|| \"public.clusternodeheartbeat\" : node_id-node_id\n",
        "    \"public.cwd_synchronisation_status\" }o--|| \"public.cwd_directory\" : id-directory_id\n",
        "    \"public.cwd_synchronisation_status\" }o--|| \"public.cwd_synchronisation_token\" : directory_id-directory_id\n",
        "    \"public.cwd_synchronisation_status\"{\n",
        "        id numeric(18)\n",
        "        directory_id numeric(18)\n",
        "        node_id varchar(60)\n",
        "        sync_start numeric(18)\n",
        "        sync_end numeric(18)\n",
        "        sync_status varchar(60)\n",
        "        status_parameters text\n",
        "    }"
      ],
      "metadata": {
        "id": "PyziaZg7YDol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Refactoring a Script"
      ],
      "metadata": {
        "id": "eBLQHloJYidD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "\n",
        "def random_sample(x: list, n: int) -> list:\n",
        "    '''This function selects a random sample of n elements froms the\n",
        "    list x without replacement and returns them in a new list\n",
        "\n",
        "    Parameters:\n",
        "        x (list): the list where the random sample is chosen from\n",
        "        n (int): the number of elements in the random sample\n",
        "\n",
        "    Returns:\n",
        "        list: a random sample of n elements from the list x in the\n",
        "             same order as the original list x\n",
        "    '''\n",
        "\n",
        "    sampled_indices = []\n",
        "\n",
        "    while len(sampled_indices) < n:\n",
        "        # A random index i is generated with this formula\n",
        "        i = math.floor(math.log(random.random()) * 1 / math.log(0.01) * len(x))\n",
        "\n",
        "        # It is checked that the index has not been already sampled\n",
        "        # and that it is within the bounds of list x\n",
        "        if i not in sampled_indices and i < len(x):\n",
        "            sampled_indices.append(i)\n",
        "\n",
        "    return [x[i] for i in sorted(sampled_indices)]"
      ],
      "metadata": {
        "id": "MMQ6M98ipIxL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Renamed the function from sfn to random_sample for clarity.\n",
        "\n",
        "-Renamed ixs to sampled_indices.\n",
        "\n",
        "-Added a docstring to provide documentation for the function.\n",
        "\n",
        "-Added comments"
      ],
      "metadata": {
        "id": "4eu82sMyp8jL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This kind of script can be used for taking subsets of data from large datasets. It could be used for example in a machine learning application to split data into test and training sets."
      ],
      "metadata": {
        "id": "RI2HmF55k1Ef"
      }
    }
  ]
}